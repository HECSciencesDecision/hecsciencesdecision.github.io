<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="pinterest" content="nopin">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">


    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/solarized_dark.min.css">
    <title>The Use of Binary Choice Forests to Model and Estimate Discrete Choices - Webinaires du département de sciences de la décision</title>
    
<meta name="description" content="Date: 9 octobre 2020 Heure: 15h00-16h00 Résumé: We show the equivalence of discrete choice models and the class of binary choice forests, which are random forests based on binary choice trees. This suggests that standard machine learning techniques based on random forests can serve to estimate discrete choice models with an interpretable output. This is confirmed by our data-driven theoretical results which show that random forests can predict the choice probability of any discrete choice model consistently, with its splitting criterion capable of recovering preference rank lists.">

<meta property="og:title" content="The Use of Binary Choice Forests to Model and Estimate Discrete Choices - Webinaires du département de sciences de la décision">
<meta property="og:type" content="article">
<meta property="og:url" content="https://HECSciencesDecision.github.io/post/a2020/2020-10-09/">
<meta property="og:image" content="https://HECSciencesDecision.github.io/images/default.png">
<meta property="og:site_name" content="Webinaires du département de sciences de la décision">
<meta property="og:description" content="Date: 9 octobre 2020 Heure: 15h00-16h00 Résumé: We show the equivalence of discrete choice models and the class of binary choice forests, which are random forests based on binary choice trees. This suggests that standard machine learning techniques based on random forests can serve to estimate discrete choice models with an interpretable output. This is confirmed by our data-driven theoretical results which show that random forests can predict the choice probability of any discrete choice model consistently, with its splitting criterion capable of recovering preference rank lists.">
<meta property="og:locale" content="ja_JP">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="Webinaires du département de sciences de la décision">
<meta name="twitter:url" content="https://HECSciencesDecision.github.io/post/a2020/2020-10-09/">
<meta name="twitter:title" content="The Use of Binary Choice Forests to Model and Estimate Discrete Choices - Webinaires du département de sciences de la décision">
<meta name="twitter:description" content="Date: 9 octobre 2020 Heure: 15h00-16h00 Résumé: We show the equivalence of discrete choice models and the class of binary choice forests, which are random forests based on binary choice trees. This suggests that standard machine learning techniques based on random forests can serve to estimate discrete choice models with an interpretable output. This is confirmed by our data-driven theoretical results which show that random forests can predict the choice probability of any discrete choice model consistently, with its splitting criterion capable of recovering preference rank lists.">
<meta name="twitter:image" content="https://HECSciencesDecision.github.io/images/default.png">


<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "NewsArticle",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id":"https:\/\/HECSciencesDecision.github.io\/"
    },
    "headline": "The Use of Binary Choice Forests to Model and Estimate Discrete Choices - Webinaires du département de sciences de la décision",
    "image": {
      "@type": "ImageObject",
      "url": "https:\/\/HECSciencesDecision.github.io\/images\/default.png",
      "height": 800,
      "width": 800
    },
    "datePublished": "2020-10-09T00:00:00JST",
    "dateModified": "2020-10-09T00:00:00JST",
    "author": {
      "@type": "Person",
      "name": "Webinaires du département de sciences de la décision"
    },
    "publisher": {
      "@type": "Organization",
      "name": "Webinaires du département de sciences de la décision",
      "logo": {
        "@type": "ImageObject",
        "url": "https:\/\/HECSciencesDecision.github.io\/images/logo.png",
        "width": 600,
        "height": 60
      }
    },
    "description": "Date: 9 octobre 2020 Heure: 15h00-16h00 Résumé: We show the equivalence of discrete choice models and the class of binary choice forests, which are random forests based on binary choice trees. This suggests that standard machine learning techniques based on random forests can serve to estimate discrete choice models with an interpretable output. This is confirmed by our data-driven theoretical results which show that random forests can predict the choice probability of any discrete choice model consistently, with its splitting criterion capable of recovering preference rank lists."
  }
</script>


    <link href="https://HECSciencesDecision.github.io/css/styles.css" rel="stylesheet">
    

  </head>

  <body>
    
    
    

    <header class="l-header">
      <nav class="navbar navbar-default">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://HECSciencesDecision.github.io/">Webinaires du département de sciences de la décision</a>
          </div>

          
          <div id="navbar" class="collapse navbar-collapse">
            
            <ul class="nav navbar-nav navbar-right">
              
              
              <li><a href="/archives/">Archives</a></li>
              
              
              
              <li><a href="/">Séminaires 2022-2023</a></li>
              
              
            </ul>
            
          </div>
          

        </div>
      </nav>
    </header>

    <main>
      <div class="container">
        
<div class="row">
  <div class="col-md-8">

    <nav class="p-crumb">
      <ol class="breadcrumb">
        <li><a href="https://HECSciencesDecision.github.io/"><i class="fa fa-home" aria-hidden="true"></i></a></li>
        
        <li itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb"><a href="https://HECSciencesDecision.github.io/post/" itemprop="url"><span itemprop="title">post</span></a></li>
        
        <li class="active">Ningyuan Chen</li>
      </ol>
    </nav>

    <article class="single">
  <header>
    <h2 class="title">The Use of Binary Choice Forests to Model and Estimate Discrete Choices</h2>
    <h3 class="post-meta">Ningyuan Chen </h3>

  </header>

  

  <div class="article-body"><h4 id="date-9-octobre-2020">Date: 9 octobre 2020</h4>
<h4 id="heure-15h00-16h00">Heure: 15h00-16h00</h4>
<h2 id="résumé">Résumé:</h2>
<p>We show the equivalence of discrete choice models and the class of binary choice forests, which are random forests based on binary choice trees. This suggests that standard machine learning techniques based on random forests can serve to estimate discrete choice models with an interpretable output. This is confirmed by our data-driven theoretical results which show that random forests can predict the choice probability of any discrete choice model consistently, with its splitting criterion capable  of recovering preference rank lists. The framework has unique advantages: it can capture behavioral patterns such as irrationality or sequential searches; it handles nonstandard formats of training data that result from aggregation; it can measure product importance based on how frequently a random customer would make decisions depending on the presence of the product; it can also incorporate price information and customer features. Our numerical results show that using random forests to estimate customer choices represented by binary choice forests can outperform the best parametric models in synthetic and real datasets. The paper can be downloaded from <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3430886">this link</a>.</p>
<h2 id="biographie-du-conférencier">Biographie du conférencier:</h2>
<p>Ningyuan Chen is assistant professor of the Department of Management at the University of Toronto, Mississauga. He received his PhD in Operations Research from Columbia University in 2015. His research interests include revenue management and dynamic pricing, networks, and statistics.</p>
</div>

  <footer class="article-footer">
  </footer>

</article>


    
  </div>

</div>

      </div>
    </main>

    <footer class="l-footer">
      <div class="container">
          <aside>
          <p><a href="https://www.hec.ca/mqg/">Département de sciences de la décision</a>, <a href="https://www.hec.ca/">HEC Montréal</a></p>
          </aside>
      </div>
    </footer>

    <script src="//code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </body>
</html>
